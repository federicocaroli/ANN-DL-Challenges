{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTXY9Ud59/4LyPtTy716yI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXRKL7TGP4h7","executionInfo":{"status":"ok","timestamp":1699991104570,"user_tz":-60,"elapsed":265256,"user":{"displayName":"federico caroli","userId":"13170733021819928222"}},"outputId":"befe65da-366c-4905-8ba5-d550500c8b38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Image 1 has 2 copies in the dataset\n","Image 3 has 2 copies in the dataset\n","Image 23 has 3 copies in the dataset\n","Image 44 has 2 copies in the dataset\n","Image 47 has 2 copies in the dataset\n","Image 54 has 2 copies in the dataset\n","Image 60 has 2 copies in the dataset\n","Image 88 has 2 copies in the dataset\n","Image 143 has 2 copies in the dataset\n","Image 148 has 3 copies in the dataset\n","Image 150 has 2 copies in the dataset\n","Image 158 has 2 copies in the dataset\n","Image 190 has 2 copies in the dataset\n","Image 191 has 2 copies in the dataset\n","Image 196 has 3 copies in the dataset\n","Image 227 has 2 copies in the dataset\n","Image 276 has 2 copies in the dataset\n","Image 284 has 2 copies in the dataset\n","Image 285 has 2 copies in the dataset\n","Image 335 has 2 copies in the dataset\n","Image 361 has 2 copies in the dataset\n","Image 380 has 2 copies in the dataset\n","Image 393 has 2 copies in the dataset\n","Image 395 has 4 copies in the dataset\n","Image 403 has 2 copies in the dataset\n","Image 436 has 2 copies in the dataset\n","Image 442 has 2 copies in the dataset\n","Image 455 has 2 copies in the dataset\n","Image 464 has 2 copies in the dataset\n","Image 501 has 2 copies in the dataset\n","Image 507 has 2 copies in the dataset\n","Image 512 has 2 copies in the dataset\n","Image 513 has 3 copies in the dataset\n","Image 552 has 2 copies in the dataset\n","Image 561 has 2 copies in the dataset\n","Image 589 has 2 copies in the dataset\n","Image 637 has 2 copies in the dataset\n","Image 640 has 2 copies in the dataset\n","Image 641 has 2 copies in the dataset\n","Image 674 has 2 copies in the dataset\n","Image 679 has 2 copies in the dataset\n","Image 719 has 2 copies in the dataset\n","Image 728 has 2 copies in the dataset\n","Image 743 has 2 copies in the dataset\n","Image 764 has 2 copies in the dataset\n","Image 766 has 2 copies in the dataset\n","Image 787 has 2 copies in the dataset\n","Image 811 has 2 copies in the dataset\n","Image 823 has 2 copies in the dataset\n","Image 849 has 3 copies in the dataset\n","Image 913 has 2 copies in the dataset\n","Image 948 has 2 copies in the dataset\n","Image 979 has 3 copies in the dataset\n","Image 1001 has 2 copies in the dataset\n","Image 1062 has 2 copies in the dataset\n","Image 1081 has 2 copies in the dataset\n","Image 1092 has 2 copies in the dataset\n","Image 1097 has 2 copies in the dataset\n","Image 1118 has 2 copies in the dataset\n","Image 1132 has 2 copies in the dataset\n","Image 1156 has 2 copies in the dataset\n","Image 1160 has 3 copies in the dataset\n","Image 1171 has 2 copies in the dataset\n","Image 1184 has 2 copies in the dataset\n","Image 1193 has 2 copies in the dataset\n","Image 1291 has 2 copies in the dataset\n","Image 1303 has 2 copies in the dataset\n","Image 1310 has 2 copies in the dataset\n","Image 1341 has 2 copies in the dataset\n","Image 1342 has 2 copies in the dataset\n","Image 1396 has 2 copies in the dataset\n","Image 1431 has 2 copies in the dataset\n","Image 1440 has 2 copies in the dataset\n","Image 1457 has 3 copies in the dataset\n","Image 1495 has 2 copies in the dataset\n","Image 1499 has 2 copies in the dataset\n","Image 1512 has 2 copies in the dataset\n","Image 1535 has 2 copies in the dataset\n","Image 1562 has 2 copies in the dataset\n","Image 1569 has 2 copies in the dataset\n","Image 1574 has 2 copies in the dataset\n","Image 1575 has 2 copies in the dataset\n","Image 1727 has 2 copies in the dataset\n","Image 1811 has 2 copies in the dataset\n","Image 1861 has 2 copies in the dataset\n","Image 1878 has 2 copies in the dataset\n","Image 1890 has 3 copies in the dataset\n","Image 1905 has 2 copies in the dataset\n","Image 1965 has 2 copies in the dataset\n","Image 1982 has 2 copies in the dataset\n","Image 2006 has 2 copies in the dataset\n","Image 2012 has 2 copies in the dataset\n","Image 2019 has 3 copies in the dataset\n","Image 2057 has 2 copies in the dataset\n","Image 2072 has 2 copies in the dataset\n","Image 2101 has 2 copies in the dataset\n","Image 2122 has 2 copies in the dataset\n","Image 2127 has 2 copies in the dataset\n","Image 2182 has 2 copies in the dataset\n","Image 2300 has 2 copies in the dataset\n","Image 2395 has 2 copies in the dataset\n","Image 2478 has 3 copies in the dataset\n","Image 2489 has 2 copies in the dataset\n","Image 2509 has 2 copies in the dataset\n","Image 2592 has 2 copies in the dataset\n","Image 2594 has 3 copies in the dataset\n","Image 2601 has 2 copies in the dataset\n","Image 2621 has 2 copies in the dataset\n","Image 2628 has 2 copies in the dataset\n","Image 2652 has 2 copies in the dataset\n","Image 2661 has 3 copies in the dataset\n","Image 2799 has 2 copies in the dataset\n","Image 2858 has 3 copies in the dataset\n","Image 2894 has 3 copies in the dataset\n","Image 2947 has 2 copies in the dataset\n","Image 3095 has 2 copies in the dataset\n","Image 3096 has 2 copies in the dataset\n","Image 3153 has 2 copies in the dataset\n","Image 3226 has 2 copies in the dataset\n","Image 3238 has 2 copies in the dataset\n","Image 3314 has 2 copies in the dataset\n","Image 3324 has 2 copies in the dataset\n","Image 3331 has 2 copies in the dataset\n","Image 3364 has 2 copies in the dataset\n","Image 3379 has 2 copies in the dataset\n","Image 3408 has 2 copies in the dataset\n","Image 3411 has 2 copies in the dataset\n","Image 3454 has 2 copies in the dataset\n","Image 3592 has 2 copies in the dataset\n","Image 3593 has 2 copies in the dataset\n","Image 3598 has 2 copies in the dataset\n","Image 3648 has 2 copies in the dataset\n","Image 3708 has 2 copies in the dataset\n","Image 3804 has 2 copies in the dataset\n","Image 3857 has 2 copies in the dataset\n","Image 4600 has 2 copies in the dataset\n","Image 4664 has 2 copies in the dataset\n","Total duplicates: {'healthy': 41, 'unhealthy': 113}\n"]}],"source":["import numpy as np\n","\n","'''\n","This script permits to create a copy of the input dataset without containing the images of Shrek and Trololo and duplicates.\n","'''\n","\n","# filename of the new collection\n","new_npz_filename = 'clean_collection.npz'\n","\n","# load the original collection file given by the teacher\n","dataset = np.load('public_data.npz', allow_pickle=True)\n","data = dataset['data']\n","\n","shrek = 58                                # The index of one Shrek image in the dataset\n","trol = 753                                # The index of one Trololo image in the dataset\n","\n","count_per_image = {}                      # For each unique image we store the number of times that we see it in the dataset\n","different_images = []                     # Each element is list containing the properties of an unique image [the label, the index in the dataset]\n","correct_images_indexes = []               # A list containing the indexes of the images that should remain in the dataset\n","\n","# Iterate on the dataset\n","for i, image in enumerate(data):\n","\n","  # If the image is equal to Shrek or equal to Trololo is skipped\n","  if np.array_equal(image, data[58]) or np.array_equal(image, data[753]):\n","    continue\n","\n","  for image_ind in count_per_image:\n","    if np.array_equal(image, data[different_images[image_ind][1]]):\n","\n","      count_per_image[image_ind] += 1     # Increase the counter\n","\n","      # If a duplicate image has a different label we print a warning (it should be impossible)\n","      if dataset['labels'][i] != different_images[image_ind][0]:\n","        print(f\"Image {i} is equal to image {different_images[image_ind][1]} but has a different label\")\n","\n","      break\n","\n","  else:\n","    # Add a new correct image\n","    correct_images_indexes.append(i)\n","    # Start the counter\n","    count_per_image[len(different_images)] = 1\n","    # Add the new unique image\n","    different_images.append((dataset['labels'][i], i))\n","\n","# Count the duplicates\n","duplicates = {\"healthy\": 0, \"unhealthy\": 0}\n","for image_ind in count_per_image:\n","  if count_per_image[image_ind] > 1:\n","    print(f\"Image {different_images[image_ind][1]} has {count_per_image[image_ind]} copies in the dataset\")\n","    if different_images[image_ind][0] == \"healthy\":\n","      duplicates[\"healthy\"] += count_per_image[image_ind] - 1\n","    elif different_images[image_ind][0] == \"unhealthy\":\n","      duplicates[\"unhealthy\"] += count_per_image[image_ind] - 1\n","    else:\n","      raise Exception(\"Impossible\")\n","\n","print(f\"Total duplicates: {duplicates}\")\n","\n","# Filter the dataset\n","non_outliers_data = data[correct_images_indexes]\n","non_outliers_labels = dataset['labels'][correct_images_indexes]\n","\n","# Save the new collection\n","np.savez(new_npz_filename, data=non_outliers_data, labels=non_outliers_labels)"]}]}