{"cells":[{"cell_type":"markdown","source":["This notebook has been used to create the five models that compose the final ensemble of 5 models submitted on Codalab.\n","The peculiarities are:\n","- They are all based on ConvNextBase pretrained model\n","- To some of them we applied resizing of the input images\n","- To some of them we applied augmentation techniques during the training phase"],"metadata":{"id":"RyqTApUk8oBK"}},{"cell_type":"markdown","metadata":{"id":"3mdPgZrf0j_Z"},"source":["Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIrLB2nt0mS0"},"outputs":[],"source":["seed = 75\n","\n","import shutil\n","import os\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","import numpy as np\n","np.random.seed(seed)\n","\n","import logging\n","\n","import random\n","random.seed(seed)\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications import ConvNeXtBase\n","from tensorflow.keras.models import Sequential\n","\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGB_IR_r_m2Y"},"outputs":[],"source":["dataset = np.load('clean_collection.npz', allow_pickle=True)\n","data = dataset['data']\n","labels = dataset['labels']\n","\n","# Cast string labels into integer values\n","casted_labels = []\n","for label in labels:\n","  if label == \"unhealthy\":\n","    casted_labels.append(1)\n","  elif label == \"healthy\":\n","    casted_labels.append(0)\n","  else:\n","    raise Exception(\"Invalid label\")\n","\n","# Expand the labels dimension moving from (x,) to (x, 1), with x cardinality\n","casted_labels = np.expand_dims(casted_labels, axis=-1)\n","\n","print(\"Training-Validation-Test Data Shape:\", data.shape)\n","print(\"Training-Validation-Test Casted Labels Shape:\", casted_labels.shape)\n","\n","# Inspect the target\n","print('Counting occurrences of target classes:')\n","unique, counts = np.unique(casted_labels, return_counts=True)\n","print(dict(zip(unique, counts)))\n","\n","x_train, x_val, y_train, y_val = train_test_split(data, casted_labels, random_state=seed, test_size=1000, stratify = casted_labels)\n","\n","del casted_labels\n","del dataset\n","del data\n","del labels\n","del unique\n","del counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8B80nxILzVQ"},"outputs":[],"source":["# Divide the heatlhy images from the unhealthy images in the training set\n","# to see the total number of healthy images and unhealthy images in the training set\n","\n","x_unhealthy = []\n","y_unhealthy = []\n","x_healthy = []\n","y_healthy = []\n","\n","for ind in range(len(x_train)):\n","  if y_train[ind][0] == 1:\n","    x_unhealthy.append(x_train[ind])\n","    y_unhealthy.append(1)\n","  elif y_train[ind][0] == 0:\n","    x_healthy.append(x_train[ind])\n","    y_healthy.append(0)\n","  else:\n","    raise Exception(\"Impossible\")\n","\n","print(f\"Len train set: {len(x_train)}  num unhealthy: {len(x_unhealthy)} num healthy: {len(x_healthy)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CcvVdmpz_wRY"},"outputs":[],"source":["# Balance the training set by adding duplicates of unhealthy images\n","# To avoid to duplicate the same unhealthy image more than one time\n","# i store the indexes of the images duplicated in a list\n","\n","indexes = []                                                    # stores the indexes of the unhealthy images already duplicated one time\n","\n","while True:\n","  # When the number of duplicated images is equal to the difference between healthy and unhealthy images\n","  # it means that we have completely balanced the training dataset\n","  if len(indexes) >= len(x_healthy) - len(x_unhealthy):\n","    break\n","\n","  tmp = np.random.randint(0, len(x_unhealthy))\n","  if tmp not in indexes:\n","    indexes.append(tmp)\n","\n","# We add the duplicated unhealthy images to the training set\n","for ind in indexes:\n","  x_unhealthy.append(x_unhealthy[ind])\n","  y_unhealthy.append(1)\n","\n","# Combining the healthy and unhealthy images of the training set into one single set\n","x_train = np.concatenate((x_unhealthy, x_healthy), axis=0)\n","y_train = np.concatenate((y_unhealthy, y_healthy), axis=0)\n","\n","y_train = np.expand_dims(y_train, axis=-1)\n","\n","\n","print(f\"Number of unhealthy images in the training set: {len(x_unhealthy)}\")\n","print(f\"Number of healthy images in the training set: {len(x_healthy)}\")\n","\n","del indexes\n","del x_unhealthy, x_healthy, y_unhealthy, y_healthy"]},{"cell_type":"markdown","metadata":{"id":"jFyqn7Iy2T0T"},"source":["Transfer Learing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOguVMTjWYtq"},"outputs":[],"source":["# Image augmentation layer composed of multiple techniques\n","img_augmentation = Sequential(\n","    [\n","        layers.RandomRotation(factor=0.17),\n","        layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n","        layers.RandomFlip(),\n","    ],\n","    name=\"img_augmentation\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imlCJy0IUopL"},"outputs":[],"source":["def build_model(pretrained_model, resize, augmentation_enabled, denses, units, dropout_rate):\n","  '''\n","  Build and return the model.\n","  - pretrained_model is the pretrained model taken from keras.applications\n","  - resize is the new size of input images\n","  - augmentation_enabled is a boolean specifying wether the augmentation layer has to be applied\n","  - denses is the number of dense layers in the top part of the network excluding the last dense layer composed of the single output neuron\n","  - units is the number of units of the first dense layer (the number of units of the following dense layers is halved each time)\n","  - dropout_rate is the dropout rate\n","  '''\n","\n","  # the model's expected input size\n","  input_shape = (96, 96, 3)\n","\n","  # The input layer\n","  inputs = layers.Input(shape=input_shape)\n","\n","  if resize != 96:\n","    # Resizing layer used to resize input images\n","    resizing = layers.Resizing(height = resize, width = resize, interpolation='bilinear', crop_to_aspect_ratio = True)\n","    # Perform resize to the wanted dimension\n","    x = resizing(inputs)\n","\n","    if augmentation_enabled:\n","      # Perform augmentation (only during training!)\n","      x = img_augmentation(x)\n","\n","    # ConvNextBase model\n","    x = pretrained_model(x)\n","\n","  elif augmentation_enabled:\n","    # Perform augmentation (only during training!)\n","    x = img_augmentation(inputs)\n","    # ConvNextBase model\n","    x = pretrained_model(x)\n","\n","  else:\n","    # ConvNextBase model\n","    x = pretrained_model(inputs)\n","\n","  # Let's rebuild the top\n","\n","  x = layers.GlobalAveragePooling2D()(x)\n","\n","  if(denses != 0):\n","\n","    # For each dense layer we specify the number of neurons, the kernel_initializer function, a batch normalization layer, the ReLU activation function and the dropout\n","    for ind in range(0, denses):\n","      x = layers.Dense(units=int(units/(2**ind)), kernel_initializer=keras.initializers.HeUniform(seed=seed))(x)\n","      x = layers.BatchNormalization()(x)\n","      x = layers.ReLU()(x)\n","      x = layers.Dropout(dropout_rate, seed=seed)(x)\n","\n","  # The output layer\n","  outputs = layers.Dense(1, activation=\"sigmoid\", name=\"pred\")(x)\n","\n","  return tf.keras.Model(inputs, outputs, name=\"model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uoBPyVD22gFJ"},"outputs":[],"source":["# We can define multiple configurations\n","# We would train and save a new model for each specified configuration\n","configs = [\n","    # ConvNext is based on the ConvNextBase pretrained model and we didn't apply both augmentation and resizing\n","    {\n","      'config_name' : \"ConvNext\",                                         # Configuration name (the name of the model directory after the save)\n","      'resize' : 96,                                                      # Resize value\n","      'augmentation_enabled': False,                                      # Wether augmentation has to be used or not during training\n","      'batch_size' : 64,                                                  # Batch size\n","      'denses' : 2,                                                       # Number of dense layers\n","      'units' : 64,                                                       # Number of units in the first dense layer\n","      'dropout_rate' : 1/8,                                               # Dropout rate\n","      'opt_transf_learn' : keras.optimizers.Adam(learning_rate = 0.01),   # Optimizer to use in the transfer learning phase\n","      'opt_fine_tuning' : keras.optimizers.Adam(),                        # Optimizer to use in the fine tuning phase\n","      'num_layer_to_freeze' : 180                                         # Number of layer to freeze during the fine tuning phase\n","    },\n","    # ConvNext_AUG is based on the ConvNextBase pretrained model and we didn't apply resizing, but we applied augmentation\n","    {\n","      'config_name' : \"ConvNext_AUG\",                                     # Configuration name (the name of the model directory after the save)\n","      'resize' : 96,                                                      # Resize value\n","      'augmentation_enabled': True,                                       # Wether augmentation has to be used or not during training\n","      'batch_size' : 64,                                                  # Batch size\n","      'denses' : 2,                                                       # Number of dense layers\n","      'units' : 64,                                                       # Number of units in the first dense layer\n","      'dropout_rate' : 1/8,                                               # Dropout rate\n","      'opt_transf_learn' : keras.optimizers.Adam(learning_rate = 0.01),   # Optimizer to use in the transfer learning phase\n","      'opt_fine_tuning' : keras.optimizers.Adam(),                        # Optimizer to use in the fine tuning phase\n","      'num_layer_to_freeze' : 180                                         # Number of layer to freeze during the fine tuning phase\n","    },\n","    # ConvNext_AUG_128 is based on the ConvNextBase pretrained model and we applied resizing to 128x128 and augmentation\n","    {\n","      'config_name' : \"ConvNext_AUG_128\",                                 # Configuration name (the name of the model directory after the save)\n","      'resize' : 128,                                                     # Resize value\n","      'augmentation_enabled': True,                                       # Wether augmentation has to be used or not during training\n","      'batch_size' : 64,                                                  # Batch size\n","      'denses' : 2,                                                       # Number of dense layers\n","      'units' : 64,                                                       # Number of units in the first dense layer\n","      'dropout_rate' : 1/8,                                               # Dropout rate\n","      'opt_transf_learn' : keras.optimizers.Adam(learning_rate = 0.01),   # Optimizer to use in the transfer learning phase\n","      'opt_fine_tuning' : keras.optimizers.Adam(),                        # Optimizer to use in the fine tuning phase\n","      'num_layer_to_freeze' : 180                                         # Number of layer to freeze during the fine tuning phase\n","    },\n","    # ConvNext_AUG_200 is based on the ConvNextBase pretrained model and we applied resizing to 200x200 and augmentation\n","    {\n","      'config_name' : \"ConvNext_AUG_200\",                                 # Configuration name (the name of the model directory after the save)\n","      'resize' : 200,                                                     # Resize value\n","      'augmentation_enabled': True,                                       # Wether augmentation has to be used or not during training\n","      'batch_size' : 64,                                                  # Batch size\n","      'denses' : 2,                                                       # Number of dense layers\n","      'units' : 64,                                                       # Number of units in the first dense layer\n","      'dropout_rate' : 1/8,                                               # Dropout rate\n","      'opt_transf_learn' : keras.optimizers.Adam(learning_rate = 0.01),   # Optimizer to use in the transfer learning phase\n","      'opt_fine_tuning' : keras.optimizers.Adam(),                        # Optimizer to use in the fine tuning phase\n","      'num_layer_to_freeze' : 180                                         # Number of layer to freeze during the fine tuning phase\n","    },\n","    # ConvNext_AUG_250 is based on the ConvNextBase pretrained model and we applied resizing to 250x250 and augmentation\n","    {\n","      'config_name' : \"ConvNext_AUG_250\",                                 # Configuration name (the name of the model directory after the save)\n","      'resize' : 250,                                                     # Resize value\n","      'augmentation_enabled': True,                                       # Wether augmentation has to be used or not during training\n","      'batch_size' : 64,                                                  # Batch size\n","      'denses' : 2,                                                       # Number of dense layers\n","      'units' : 64,                                                       # Number of units in the first dense layer\n","      'dropout_rate' : 1/8,                                               # Dropout rate\n","      'opt_transf_learn' : keras.optimizers.Adam(learning_rate = 0.01),   # Optimizer to use in the transfer learning phase\n","      'opt_fine_tuning' : keras.optimizers.Adam(),                        # Optimizer to use in the fine tuning phase\n","      'num_layer_to_freeze' : 180                                         # Number of layer to freeze during the fine tuning phase\n","    }\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RU6JrB1i1vFe"},"outputs":[],"source":["# Standard parameters\n","\n","patience = 15\n","epochs_transf_learn = 10\n","epochs_fine_tuning = 200\n","\n","lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_accuracy',                                             # Metric to monitor (validation accuracy in this case)\n","    patience=3,                                                         # Number of epochs with no improvement after which learning rate will be reduced\n","    factor=0.9,                                                         # Factor by which the learning rate will be reduced (0.9 in this case)\n","    mode='max',                                                         # Mode to decide when to reduce learning rate\n","    min_lr=1e-5                                                         # Minimum learning rate\n",")\n","\n","early_stopping = keras.callbacks.EarlyStopping(\n","    monitor='val_accuracy',\n","    mode='max',\n","    patience=patience,\n","    restore_best_weights=True\n",")\n","\n","callbacks = [early_stopping, lr_scheduler]\n","\n","\n","# Iterate the configurations\n","\n","for config in configs:\n","\n","  config_name = config['config_name']\n","  resize = config['resize']\n","  augmentation_enabled = config['augmentation_enabled']\n","  batch_size = config['batch_size']\n","  denses = config['denses']\n","  units = config['units']\n","  dropout_rate = config['dropout_rate']\n","  opt_transf_learn = config['opt_transf_learn']\n","  opt_fine_tuning = config['opt_fine_tuning']\n","  num_layer_to_freeze = config['num_layer_to_freeze']\n","\n","  print(f\"\\n\\nConfiguration in use: {config_name}\\n\\n\")\n","\n","  # Instantiate pretrained model\n","  pretrained_model = ConvNeXtBase(\n","    include_top=False,\n","    weights=\"imagenet\",\n","  )\n","\n","  for layer in pretrained_model.layers:\n","    layer.trainable = False\n","\n","  # Build the model\n","  model = build_model(\n","    pretrained_model,\n","    resize,\n","    augmentation_enabled,\n","    denses,\n","    units,\n","    dropout_rate\n","  )\n","\n","  # Start the transfer learning phase\n","\n","  model.compile(\n","    optimizer=opt_transf_learn,\n","    loss=keras.losses.BinaryCrossentropy(),\n","    metrics=[\"accuracy\"]\n","  )\n","\n","  # Start the training in the transfer learning phase and save the history\n","  tl_history = model.fit(\n","    x = x_train,\n","    y = y_train,\n","    batch_size = batch_size,\n","    epochs = epochs_transf_learn,\n","    validation_data=(x_val, y_val),\n","    callbacks = callbacks\n","  ).history\n","\n","\n","  # Start the fine tuning phase\n","\n","  # Set all ConvNextBase layers to trainable\n","  model.get_layer('convnext_base').trainable = True\n","  # Now let's freeze first -num_layer_to_freeze- layers\n","  for i, layer in enumerate(model.get_layer('convnext_base').layers[:num_layer_to_freeze]):\n","    layer.trainable=False\n","\n","  model.compile(\n","    optimizer=opt_fine_tuning,\n","    loss=keras.losses.BinaryCrossentropy(),\n","    metrics=[\"accuracy\"]\n","  )\n","\n","  # Start the training in the fine tuning phase and save the history\n","  ft_history = model.fit(\n","    x = x_train,\n","    y = y_train,\n","    batch_size = batch_size,\n","    epochs=epochs_fine_tuning,\n","    validation_data=(x_val, y_val),\n","    callbacks = callbacks\n","  ).history\n","\n","\n","  # Show the plots\n","\n","  # Plot the transfer learning and the fine-tuned training histories\n","  plt.figure(figsize=(15,5))\n","  plt.plot(tl_history['loss'], label='Transfer Learning Training Loss', alpha=.3, color='#4D61E2', linestyle='--')\n","  plt.plot(tl_history['val_loss'], label='Transfer Learning Validation Loss', alpha=.8, color='#4D61E2')\n","  plt.plot(ft_history['loss'], label='Fine Tuning Training Loss' ,alpha=.3, color='#408537', linestyle='--')\n","  plt.plot(ft_history['val_loss'], label='Fine Tuning Validation Loss', alpha=.8, color='#408537')\n","  plt.legend(loc='upper left')\n","  plt.title('Binary Crossentropy')\n","  plt.grid(alpha=.3)\n","\n","  plt.figure(figsize=(15,5))\n","  plt.plot(tl_history['accuracy'], label='Transfer Learning Training Accuracy', alpha=.3, color='#4D61E2', linestyle='--')\n","  plt.plot(tl_history['val_accuracy'], label='Transfer Learning Validation Accuracy', alpha=.8, color='#4D61E2')\n","  plt.plot(ft_history['accuracy'], label='Fine Tuning Training Accuracy' ,alpha=.3, color='#408537', linestyle='--')\n","  plt.plot(ft_history['val_accuracy'], label='Fine Tuning Validation Accuracy', alpha=.8, color='#408537')\n","  plt.legend(loc='upper left')\n","  plt.title('Accuracy')\n","  plt.grid(alpha=.3)\n","\n","  plt.show()\n","\n","  # Validation Accuracy, F1, Precision, Recall computation\n","\n","  val_predictions = model.predict(x_val, verbose=0)\n","  val_predictions = tf.where(val_predictions < 0.5, 0, 1)\n","  val_predictions = val_predictions.numpy()\n","\n","  # Compute scores\n","  val_accuracy = accuracy_score(y_val, val_predictions)\n","  val_f1 = f1_score(y_val, val_predictions)\n","  val_precision = precision_score(y_val, val_predictions)\n","  val_recall = recall_score(y_val, val_predictions)\n","\n","  # Display the computed metrics\n","  print('Val Accuracy:', val_accuracy.round(4))\n","  print('Val F1:', val_f1.round(4))\n","  print('Val Precision:', val_precision.round(4))\n","  print('Val Recall:', val_recall.round(4))\n","\n","  # Save the model\n","  model.save(config_name)\n","\n","  # Explicit deletes to avoid waiting the garbage collector\n","  del config_name, resize, augmentation_enabled, batch_size, denses, units, dropout_rate, opt_transf_learn, opt_fine_tuning, num_layer_to_freeze\n","  del pretrained_model, model, tl_history, ft_history\n","  del val_predictions, val_accuracy, val_f1, val_precision, val_recall\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1DjlEoizq4sfyLWykl79HdNOcPQOMy-8u","timestamp":1699823401857},{"file_id":"1HtlC1NXou0pzQcGMS1YojqdoDurVCgKD","timestamp":1699788046823},{"file_id":"1_Y55hiaYWO98LqnZwr4sSHBjVeQbmX7Y","timestamp":1699387112050}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}