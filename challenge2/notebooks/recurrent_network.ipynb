{"cells":[{"cell_type":"markdown","metadata":{"id":"eqLLlrl_ga1r"},"source":["Connect to Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XIEN0N88mIMf"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/ANNDL Challenge2"]},{"cell_type":"markdown","metadata":{"id":"TIiXZm8xKzWn"},"source":["# Summary\n","\n","In this notebook is shown how we built a model based on either the original series or the stationary series or the detrended series (it can be decided using a variable).\n","\n","In this notebook is possible to see how we handled stationary / detrended series to allow the model to train. Furthermore, is possible to see how we handle the stationary / detrended predictions done by the model with the objective of obtaining back the prediction in the original domain."]},{"cell_type":"markdown","metadata":{"id":"pQIRTdzkg2OV"},"source":["Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jfnGMmJnQ5G"},"outputs":[],"source":["# Fix randomness and hide warnings\n","seed = 42\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","import numpy as np\n","np.random.seed(seed)\n","\n","import logging\n","\n","import random\n","random.seed(seed)\n","\n","\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLusodRrnSi5"},"outputs":[],"source":["# Import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","print(tf.__version__)"]},{"cell_type":"markdown","source":["Choose the type of time series you want to use"],"metadata":{"id":"E12EdeVITaP3"}},{"cell_type":"code","source":["USING_ORIGINAL_SERIES = 1\n","USING_DETRENDED_SERIES = 2                                                      # If we decide to use the detrended series we don't consider and compute the seasonalities of the series\n","USING_STATIONARY_SERIES = 3\n","\n","timeSeriesToUse = USING_DETRENDED_SERIES\n","\n","if timeSeriesToUse not in [USING_ORIGINAL_SERIES, USING_DETRENDED_SERIES, USING_STATIONARY_SERIES]:\n","  raise Exception(\"Invalid value!\")"],"metadata":{"id":"qDVd9ud6TjKS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"csmMvS8nhHc_"},"source":["Resources Paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMGdnJmThIDC"},"outputs":[],"source":["trainDataFile = \"./fullTrainData.npy\"\n","validationDataFile = \"./fullValidationData.npy\""]},{"cell_type":"markdown","metadata":{"id":"M5AjiCsnjeWT"},"source":["Variables initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xnDEd_BinT7b"},"outputs":[],"source":["trainData = np.load(trainDataFile, allow_pickle=True)\n","validationData = np.load(validationDataFile, allow_pickle=True)\n","\n","# For each set we consider the original series, the rolling mean series, the detrended series, the periodicity, the stationary series\n","# because they are all necessary information to do the reverse process from stationary series to original series\n","labels = {'originalSeries': 0, 'rollingMeanSeries': 1, 'detrendedSeries': 2, 'seasonalityIndexOfSeries': 3, 'stationarySeries': 4}"]},{"cell_type":"markdown","metadata":{"id":"IWyIc8atjopA"},"source":["### Manipulating the input dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMhfDeeFo-ly"},"outputs":[],"source":["def build_sequences(series, window=300, stride=50, telescope=9):\n","  '''\n","  Split the single 'series' in multiple blocks of length 'window'. Each block is composed of a x part of length 'window' - 'telescope' and a y part of length 'telescope'.\n","  'Data\n","  'Window' is the length of the input of our network\n","  'Stride' is the number of samples to skip before starting the next window\n","  'Telescope' is the length of the output of our network\n","  '''\n","  blocks = []\n","  labels = []\n","  idx = 0\n","\n","  # We divide a time series in multiple blocks\n","  # If the series length is not a multiple of the window size, then the remaining slice of the series is skipped\n","  while(idx + window <= len(series)):\n","    blocks.append(series[idx : (idx + window - telescope)])\n","    labels.append(series[(idx + window - telescope) : (idx + window)])\n","    idx += stride\n","\n","  blocks = np.array(blocks)\n","  labels = np.array(labels)\n","  return np.array(blocks), np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujkSHUzTm6qx"},"outputs":[],"source":["def compute_sequences_for_dataset(data, window, stride, telescope, minimum_length):\n","  '''\n","  Using the build_sequences function to increase the number of samples.\n","  'Data' is a list containing the starting series.\n","  'Window' is the length of the input of our network plus the telescope\n","  'Stride' is the number of samples to skip before starting the next window\n","  'Telescope' is the length of the output of our network\n","  'Minimum_length' is the minimum length that a series must have to be considered\n","  '''\n","\n","  x = []\n","  y = []\n","\n","  # Compute the various sequences for each stationary series in data\n","  for series in data:\n","\n","    # We skip the series with length less than the chosen 'minimum_length'\n","    if (len(series) >= minimum_length):\n","\n","      # If the series length is less than the window size we need to pad the series\n","      if (len(series) < window):\n","        padding_len = window - len(series)\n","\n","        # We isolate the Y portion (the telescope part) to let us adding the padding at the end of the X portion\n","        temp = series[ len(series) - telescope : len(series)]\n","\n","        # We isolate the X portion\n","        series  = series[0 : len(series) - telescope]\n","\n","        # We create the padding as a series full of 2-s\n","        padding = np.full((padding_len), 2, dtype= 'float32')\n","\n","        # Our resulting series is composed of the X portion, the padding and the Y portion\n","        series = np.concatenate((series, padding, temp))\n","\n","      # the X portions of the blocks and the Y portions of the blocks are computed\n","      x_new, y_new = build_sequences(series, window, stride, telescope)\n","\n","      for elem in x_new:\n","        x.append(elem)\n","      for elem in y_new:\n","        y.append(elem)\n","\n","  x = np.array(x)\n","  y = np.array(y)\n","\n","  return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pq_fPtXFphMc"},"outputs":[],"source":["# Define common variables\n","\n","window = 218\n","telescope = 18"]},{"cell_type":"markdown","metadata":{"id":"BGHRChLTmnKj"},"source":["Using the build_sequences function to increase the number of samples in the training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2qusQ4-opDL"},"outputs":[],"source":["# Using the build_sequences function to increase the number of samples in the training set\n","\n","train_x = []\n","train_y = []\n","stride = 10\n","\n","if timeSeriesToUse == USING_STATIONARY_SERIES:\n","  # Compute the various sequences for each stationary series in the training set\n","  data_to_use = trainData[labels['stationarySeries']]\n","elif timeSeriesToUse == USING_DETRENDED_SERIES:\n","  # Compute the various sequences for each detrended series in the training set\n","  data_to_use = trainData[labels['detrendedSeries']]\n","else:\n","  # Compute the various sequences for each original series in the training set\n","  data_to_use = trainData[labels['originalSeries']]\n","\n","train_x, train_y = compute_sequences_for_dataset(data_to_use, window, stride, telescope, 80)\n","\n","train_x = np.expand_dims(train_x, axis= 2)\n","\n","print(train_x.shape)\n","print(train_y.shape)\n","print(f\"Original number of sequences: {len(data_to_use)}\")\n","print(f\"Number of total sequences: {len(train_x)}\")\n","print(f'By choosing a window equal to {window} and stride equal to {stride}, there are {len(train_x) - len(data_to_use)} more time series')"]},{"cell_type":"markdown","metadata":{"id":"6W3ajhcLmpvQ"},"source":["Using the build_sequences function to increase the number of samples in the validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_L63t5ApYon"},"outputs":[],"source":["# Using the build_sequences function to increase the number of samples in the validation set\n","\n","val_x = []\n","val_y = []\n","\n","if timeSeriesToUse == USING_STATIONARY_SERIES:\n","  # Compute the various sequences for each stationary series in the validation set\n","  data_to_use = validationData[labels['stationarySeries']]\n","\n","elif timeSeriesToUse == USING_DETRENDED_SERIES:\n","  # Compute the various sequences for each detrended series in the validation set\n","  data_to_use = validationData[labels['detrendedSeries']]\n","\n","else:\n","  # Compute the various sequences for each original series in the validation set\n","  data_to_use = validationData[labels['originalSeries']]\n","\n","# In this case we use a stride equal to window because we don't want the validation samples to be overlapped\n","val_x, val_y = compute_sequences_for_dataset(data_to_use, window, window, telescope, 50)\n","\n","val_x = np.expand_dims(val_x, axis= 2)\n","\n","print(val_x.shape)\n","print(val_y.shape)\n","print(f\"Original number of sequences: {len(data_to_use)}\")\n","print(f\"Number of total sequences: {len(val_x)}\")\n","print(f'By choosing a window equal to {window} and a stride equal to {window}, there are {len(val_x) - len(data_to_use)} more time series')"]},{"cell_type":"markdown","metadata":{"id":"gybABmubp454"},"source":["### Developing the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsjfQauppS5q"},"outputs":[],"source":["# Define common variables\n","input_shape = [window - telescope, 1]\n","output_shape = [telescope]\n","batch_size = 64\n","epochs = 200\n","\n","save_the_model_on_file = False                                                  # Flag that says if it should save the model on file\n","model_file = \"./tmp/model\"                                                      # The model file path"]},{"cell_type":"markdown","metadata":{"id":"c9nBiuXeropA"},"source":["Define the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0i5IGQmpUHl"},"outputs":[],"source":["def build_LSTM_model(input_shape, output_shape):\n","\n","    # Define the input layer with the specified shape\n","    input_layer = tfkl.Input(shape=input_shape)\n","\n","    # Masking Layer\n","    x = tfkl.Masking(mask_value= 2, input_shape= input_shape)(input_layer)\n","\n","    # Add two Bidirectional LSTM layer with 64 units\n","    x = tfkl.Bidirectional(tfkl.LSTM(256, return_sequences=True, name='lstm'), name='bidirectional_lstm')(x)\n","    x = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True, name='lstm'), name='bidirectional_lstm_2')(x)\n","    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=False, name='lstm'), name='bidirectional_lstm_3')(x)\n","\n","    output_layer = tfkl.Dense(output_shape[0])(x)\n","\n","    # Construct the model by connecting input and output layers\n","    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='LSTM_model')\n","\n","    # Compile the model with Mean Squared Error loss and Adam optimizer\n","    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"Hl9klVXUr6WG"},"source":["Train the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7Xg5FFepVju"},"outputs":[],"source":["# Create the model\n","model = build_LSTM_model(input_shape, output_shape)\n","model.summary()\n","\n","# Train the model\n","history = model.fit(\n","    x = train_x,\n","    y = train_y,\n","    batch_size = batch_size,\n","    epochs = epochs,\n","    validation_data=(val_x, val_y),\n","    callbacks = [\n","        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n","        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3, factor=0.9, min_lr=1e-5)\n","    ]\n",").history\n","\n","#Plot loss\n","best_epoch = np.argmin(history['val_loss'])\n","plt.figure(figsize=(17,4))\n","plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n","plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.title('Mean Squared Error')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()\n","\n","plt.figure(figsize=(18,3))\n","plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gCym1fnrRLaW"},"outputs":[],"source":["if save_the_model_on_file:\n","  model.save(model_file)\n","  del model\n","\n","  model = tfk.models.load_model(model_file)"]},{"cell_type":"markdown","metadata":{"id":"eqYBpWQ3ukSu"},"source":["### Inferences on predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zDgVV9CFKKW"},"outputs":[],"source":["def splitToObtainFixedLenghtSeries(dataset, seasonalities, window, telescope):\n","  '''\n","  It permits to have blocks of length 'window', each one containing a fixed number of completed periods of the starting stationary series.\n","  Split each series included in 'dataset' in multiple blocks of fixed length equal to 'window'.\n","  Each block is composed of a X part and a Y part. Each block contains a discrete number of periods of the original series.\n","  'Dataset' is the list of input series.\n","  'Seasonalities' is a list containing the periodicity (a number) for each series\n","  'Window' is the length of each block (composed of two parts: X and Y)\n","  'Telescope' is the length of the Y portion of the block (The portion composed of the \"\"future\"\" samples to predict)\n","  '''\n","\n","  x = []\n","  y = []\n","  resulting_seasonalities = []\n","\n","  for index in range(0, len(dataset)):\n","    # If the periodicity of the series is greater than the window length it is skipped because no period can be entirely contained in a single block\n","    if seasonalities[index] > window:\n","      continue\n","\n","    # The actual window size must be a multiple of the periodicity of the series\n","    multiple_window = int(window / seasonalities[index]) * seasonalities[index]\n","    # The remaining space in the block is filled using padding\n","    padding_length = window - multiple_window\n","\n","    # Number of blocks resulting from this split for a single series\n","    num_blocks = int(len(dataset[index]) / multiple_window)\n","\n","    # We avoid using the remaining slice (the last not full block)\n","    for block_ind in range(0, num_blocks):\n","\n","      # Isolate the current block\n","      block = dataset[index][block_ind * multiple_window : (block_ind + 1) * multiple_window]\n","\n","      # Isolate the real X portion of the block\n","      tmp = np.copy(block[ : multiple_window - telescope])\n","\n","      # Create the pad sequence, full of 2-s\n","      pad = np.full(shape = padding_length, fill_value = 2)\n","\n","      # Create the X portion of the block. It is composed of the real X portion of the block and the pad sequence\n","      x.append(np.append(tmp,pad))\n","\n","      # Isolate the Y portion of the block\n","      y.append(np.copy(block[multiple_window - telescope : ]))\n","\n","      # For each block we store the its seasonality (it is equal to the periodicity of the original series)\n","      resulting_seasonalities.append(seasonalities[index])\n","\n","  return np.array(x), np.array(y), np.array(resulting_seasonalities)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZsHhlehBKyO"},"outputs":[],"source":["def reverseStationarity(predictions, original_series_val_x, detrended_series, seasonalities):\n","\t'''\n","    Transform the stationary predictions in the predictions based on the original domain.\n","    'Predictions' is the list of the stationary predictions computed by the network.\n","    'Original_series_val_x' is the list of the X portion of the series based on the original domain.\n","\t'Detrended_series' is the list of the corrispondent detrended X portions.\n","\t'Seasonalities' is the list composed of the periodicity (it is a number) of each series.\n","    '''\n","\n","\toriginal_predictions = []\t\t\t\t\t\t\t\t\t\t\t\t\t# The predicions done by the network moved in the original domain.\n","\trolling_window = 5\n","\n","\tfor index in range(0, len(predictions)):\n","\n","\t\t\tdetrended_prediction = []\t\t\t\t\t\t\t\t\t\t\t# The computed detrended prediction (starting from the stationary prediction)\n","\t\t\toriginal_prediction = []\t\t\t\t\t\t\t\t\t\t\t# The computed original prediction (starting from the stationary prediction)\n","\t\t\ttmp_detrended_series = np.copy(detrended_series[index])\n","\t\t\ttmp_original_series_val_x = np.copy(original_series_val_x[index])\n","\n","\t\t\t# Compute the detrended prediction\n","\t\t\tfor prediction_index in range(0, len(predictions[index])):\n","\t\t\t\t\tdetrended_prediction.append(predictions[index][prediction_index] + tmp_detrended_series[len(tmp_detrended_series) - seasonalities[index]])\n","\t\t\t\t\ttmp_detrended_series = np.concatenate((tmp_detrended_series, np.array([detrended_prediction[prediction_index]])))\n","\n","\t\t\t# Compute the rolling mean series and the original prediction\n","\t\t\tfor prediction_index in range(0, len(detrended_prediction)):\n","\t\t\t\t\trolling_mean = np.mean(np.array(tmp_original_series_val_x[len(tmp_original_series_val_x) - rolling_window : ]))\n","\t\t\t\t\toriginal_prediction.append(predictions[index][prediction_index] + rolling_mean)\n","\t\t\t\t\ttmp_original_series_val_x = np.concatenate((tmp_original_series_val_x, np.array([original_prediction[prediction_index]])))\n","\n","\t\t\toriginal_predictions.append(original_prediction)\n","\n","\treturn np.array(original_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTOyz4qxE_EN"},"outputs":[],"source":["def reverseDetrend(predictions, original_series_val_x):\n","    '''\n","    Transform the detrended predictions in the predictions based on the original domain.\n","    'Predictions' is the list of the detrended predictions computed by the network.\n","    'Original_series_val_x' is the list of the X portion of the series based on the original domain.\n","    '''\n","\n","    original_predictions = []\n","    rolling_window = 5\n","\n","    # For each detrended prediction we compute the corrispondent prediction in the original domain\n","    for index in range(0, len(predictions)):\n","        original_prediction = []\n","        tmp_original_series_val_x = np.copy(original_series_val_x[index])\n","\n","        for prediction_index in range(0, len(predictions[index])):\n","            rolling_mean = np.mean(np.array(tmp_original_series_val_x[len(tmp_original_series_val_x) - rolling_window : ]))\n","            original_prediction.append(predictions[index][prediction_index] + rolling_mean)\n","            tmp_original_series_val_x = np.concatenate((tmp_original_series_val_x, np.array([original_prediction[prediction_index]])))\n","\n","        original_predictions.append(original_prediction)\n","\n","    return np.array(original_predictions)"]},{"cell_type":"markdown","metadata":{"id":"zLDrh7ClDYv2"},"source":["Preparing the stationary series to use as input and the corrispondent Y portion composed of the future sample to predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59UyOSjvGRM9"},"outputs":[],"source":["stationarity_series_val_x = []                                                  # List containing the X portion of each computed block for the stationary series\n","stationarity_series_val_y = []                                                  # List containing the Y portion of each computed block for the stationary series\n","original_series_val_x = []                                                      # List containing the X portion of each computed block for the original series\n","original_series_val_y = []                                                      # List containing the Y portion of each computed block for the original series\n","detrend_series_val_x = []                                                       # List containing the X portion of each computed block for the detrended series\n","detrend_series_val_y = []                                                       # List containing the Y portion of each computed block for the detrended series\n","\n","all_series_seasonalities = []                                                   # List containing the periodicity of each computed block (it is equivalent for stationary series, detrended series, original series and rolling mean series)\n","\n","if timeSeriesToUse == USING_STATIONARY_SERIES:\n","  # Compute the various blocks of the stationary series and the corrispondent detrended series and original series and compute the periodicity of each block\n","  stationarity_series_val_x, stationarity_series_val_y, all_series_seasonalities = splitToObtainFixedLenghtSeries(validationData[labels['stationarySeries']], validationData[labels['seasonalityIndexOfSeries']], window, telescope)\n","  original_series_val_x, original_series_val_y, all_series_seasonalities = splitToObtainFixedLenghtSeries(validationData[labels['originalSeries']], validationData[labels['seasonalityIndexOfSeries']], window, telescope)\n","  detrend_series_val_x, detrend_series_val_y, all_series_seasonalities = splitToObtainFixedLenghtSeries(validationData[labels['detrendedSeries']], validationData[labels['seasonalityIndexOfSeries']], window, telescope)\n","\n","  stationarity_series_val_x = np.expand_dims(stationarity_series_val_x, axis= 2)\n","\n","elif timeSeriesToUse == USING_DETRENDED_SERIES:\n","  # Compute the sequences for each original series in the validation set, because they will be used to reverse the detrended predictions\n","  original_series_val_x, original_series_val_y = compute_sequences_for_dataset(validationData[labels['originalSeries']], window, window, telescope, 50)\n","\n","else:\n","  original_series_val_x, original_series_val_y = val_x, val_y"]},{"cell_type":"markdown","metadata":{"id":"5xCu4Gt8DI52"},"source":["Make the predictions using stationary series as input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GqArqNAnLhgo"},"outputs":[],"source":["if timeSeriesToUse == USING_STATIONARY_SERIES:\n","    predictions = model.predict(stationarity_series_val_x)\n","else:\n","    predictions = model.predict(val_x)"]},{"cell_type":"markdown","metadata":{"id":"odoP-IuWDbqK"},"source":["Inference the predictions and compute the MSE and MAE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UEgOxbOdKluH"},"outputs":[],"source":["# Remove the padding values from the X portion of the various blocks\n","\n","if timeSeriesToUse == USING_STATIONARY_SERIES:\n","  iter = np.copy(original_series_val_x)\n","  original_series_val_x = []\n","  for series in iter:\n","    indices_padding = np.where(series == 2)\n","    original_series_val_x.append(np.delete(series, indices_padding))\n","\n","  iter = np.copy(detrend_series_val_x)\n","  detrend_series_val_x = []\n","  for series in iter:\n","    indices_padding = np.where(series == 2)\n","    detrend_series_val_x.append(np.delete(series, indices_padding))\n","\n","  # Transform the stationary prediction into prediction based in the original domain\n","  original_predictions = reverseStationarity(predictions, original_series_val_x, detrend_series_val_x, all_series_seasonalities)\n","\n","elif timeSeriesToUse == USING_DETRENDED_SERIES:\n","  iter = np.copy(original_series_val_x)\n","  original_series_val_x = []\n","  for series in iter:\n","    indices_padding = np.where(series == 2)\n","    original_series_val_x.append(np.delete(series, indices_padding))\n","\n","  # Transform the detrended prediction into prediction based in the original domain\n","  original_predictions = reverseDetrend(predictions, original_series_val_x)\n","\n","else:\n","  original_predictions = predictions\n","\n","# Calculate and print Mean Squared Error (MSE)\n","mean_squared_error = tfk.metrics.mean_squared_error(original_series_val_y.flatten(), original_predictions.flatten()).numpy()\n","print(f\"Mean Squared Error: {mean_squared_error}\")\n","\n","# Calculate and print Mean Absolute Error (MAE)\n","mean_absolute_error = tfk.metrics.mean_absolute_error(original_series_val_y.flatten(), original_predictions.flatten()).numpy()\n","print(f\"Mean Absolute Error: {mean_absolute_error}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Buu0ds31N9hz"},"outputs":[],"source":["def inspect_timeseries_predictions(X, Y, preds, num, telescope):\n","    '''\n","    Randomly plot a number 'num' of series composed by the known x portion and the true y portion and the predicted portion.\n","    'X' is a list containing all the available x portions.\n","    'Y' is a list containing all the available y portions (the true).\n","    'Preds' is a list containing all the predicted y portions (the predictions).\n","    'Num' is the number of series to plot.\n","    'Telescope' is the length of each y portion (it is valid also for the length of each predicted portion).\n","    '''\n","\n","    figs, axs = plt.subplots(num, 1, sharex=True, figsize=(17,17))\n","    for i in range(0, num):\n","        idx=np.random.randint(0,len(X))\n","        axs[i].plot(np.arange(len(X[idx])), X[idx])\n","        axs[i].plot(np.arange(len(X[idx]), len(X[idx])+telescope), Y[idx], color='orange')\n","        axs[i].plot(np.arange(len(X[idx]), len(X[idx])+telescope), preds[idx], color='green')\n","        axs[i].set_ylim(-1,1)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzQsvp3IOAHu"},"outputs":[],"source":["# Plot some predictions\n","inspect_timeseries_predictions(original_series_val_x, original_series_val_y, original_predictions, 10, telescope)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}